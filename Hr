from pyspark import SparkConf, SparkContext
from pyspark.rdd import RDD
import sys

# Define the Article class
class Article:
    def __init__(self, article_id=None, article_text=""):
        self.article_id = article_id
        self.article_text = article_text

    def parse(self, line: str):
        """Parses a line in the format 'article_id|article_text'"""
        tokens = line.split("|", 1)
        if len(tokens) == 2:
            self.article_id = int(tokens[0])
            self.article_text = tokens[1].strip()
        return self

    def __repr__(self):
        return f"{self.article_id}|{self.article_text}"

# Define the PySpark Job
class PySparkJob:
    def __init__(self):
        """Initialize the Spark context."""
        conf = SparkConf().setMaster("local").setAppName("Spell Checker Job")
        self.sc = SparkContext(conf=conf)

    def read_file(self, input_path: str) -> RDD:
        """Reads a text file and returns an RDD of Article objects."""
        return self.sc.textFile(input_path).map(lambda line: Article().parse(line))

    def keep_nonempty_articles(self, articles: RDD) -> RDD:
        """Filters out empty articles."""
        return articles.filter(lambda article: article.article_text.strip() != "")

    def load_dictionary(self, dict_path: str) -> dict:
        """Loads the dictionary of misspelled words and corrections."""
        return dict(self.sc.textFile(dict_path)
                    .map(lambda line: tuple(line.split(",")))
                    .collect())

    def calculate_misspelled_percentage(self, article: Article, dictionary: dict) -> float:
        """Calculates the percentage of misspelled words in an article."""
        words = article.article_text.split()
        if not words:
            return 0.0
        misspelled_count = sum(1 for word in words if word in dictionary)
        return misspelled_count / len(words)

    def find_good_articles(self, articles: RDD, dictionary: dict) -> RDD:
        """Finds good articles (â‰¤30% misspelled words)."""
        return articles.filter(lambda article: self.calculate_misspelled_percentage(article, dictionary) <= 0.3)

    def find_bad_articles(self, articles: RDD, dictionary: dict) -> RDD:
        """Finds bad articles (>30% misspelled words)."""
        return articles.filter(lambda article: self.calculate_misspelled_percentage(article, dictionary) > 0.3)

    def save_as(self, rdd: RDD, output_path: str) -> None:
        """Saves RDD of articles to a file."""
        rdd.map(lambda article: f"{article.article_id}|{article.article_text}").saveAsTextFile(output_path)

    def run(self, dict_path: str, article_path: str, good_article_output: str, bad_article_output: str):
        """Main execution workflow."""
        print("<<Reading Dictionary>>")
        dictionary = self.load_dictionary(dict_path)

        print("<<Reading Articles>>")
        articles = self.read_file(article_path)
        print(f"Total Articles: {articles.count()}")

        print("<<Filtering Empty Articles>>")
        nonempty_articles = self.keep_nonempty_articles(articles).cache()
        print(f"Non-empty Articles: {nonempty_articles.count()}")

        print("<<Finding Good Articles>>")
        good_articles = self.find_good_articles(nonempty_articles, dictionary)
        print(f"Good Articles: {good_articles.count()}")

        print("<<Finding Bad Articles>>")
        bad_articles = self.find_bad_articles(nonempty_articles, dictionary)
        print(f"Bad Articles: {bad_articles.count()}")

        print("<<Saving Results>>")
        self.save_as(good_articles, good_article_output)
        self.save_as(bad_articles, bad_article_output)
        print("<<Job Completed>>")

# Entry Point
if __name__ == "__main__":
    if len(sys.argv) != 5:
        print("Usage: python3 app.py <dict_path> <article_path> <good_article_output> <bad_article_output>")
        sys.exit(1)

    dict_path = sys.argv[1]
    article_path = sys.argv[2]
    good_article_output = sys.argv[3]
    bad_article_output = sys.argv[4]

    job = PySparkJob()
    job.run(dict_path, article_path, good_article_output, bad_article_output)
